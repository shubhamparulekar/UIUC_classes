{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e38914",
   "metadata": {},
   "source": [
    "This notebook illustrates:  \n",
    "(1) Various feature selection techniques and evaluation schemes on the movie review dataset;  \n",
    "(2) Model comparison using cross-validation and paired t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc4779",
   "metadata": {},
   "source": [
    "# 1. Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc408f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train set:  10000\n",
      "Original test set:  2500\n",
      "After removing empty reviews, train set size:  10000\n",
      "After removing empty reviews, test set size:  2500\n",
      "After removing instances with no labels, train set size:  10000\n",
      "After removing instances with no labels, test set size:  2500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_file = \"movie_train.csv\"\n",
    "test_data_file = \"movie_test.csv\"\n",
    "\n",
    "# Import train and test dataset into data frames and print out the original lengths\n",
    "train_data_df = pd.read_csv(train_data_file)\n",
    "test_data_df = pd.read_csv(test_data_file)\n",
    "print (\"Original train set: \",len(train_data_df))\n",
    "print (\"Original test set: \",len(test_data_df))\n",
    "\n",
    "### CLEAN DATASETS ###\n",
    "# Remove empty rows from both sets and print out the new lengths\n",
    "train_data_df = train_data_df[~train_data_df[\"review\"].isnull()]\n",
    "test_data_df = test_data_df[~test_data_df[\"review\"].isnull()]\n",
    "print (\"After removing empty reviews, train set size: \",len(train_data_df))\n",
    "print (\"After removing empty reviews, test set size: \",len(test_data_df))\n",
    "\n",
    "# Remove rows with null labels\n",
    "train_data_df = train_data_df[~train_data_df[\"sentiment\"].isnull()]\n",
    "test_data_df = test_data_df[~test_data_df[\"sentiment\"].isnull()]\n",
    "print (\"After removing instances with no labels, train set size: \", len(train_data_df))\n",
    "print (\"After removing instances with no labels, test set size: \", len(test_data_df))\n",
    "\n",
    "# print out top 5 rows of the train set\n",
    "display(train_data_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435e36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use original reviews for model building\n",
    "y_train = train_data_df[\"sentiment\"]\n",
    "y_test = test_data_df[\"sentiment\"]\n",
    "\n",
    "train_text = train_data_df[\"review\"]\n",
    "test_text = test_data_df[\"review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e94f1a",
   "metadata": {},
   "source": [
    "### Count-based feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4c2ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52522\n",
      "[('one', 32799), ('of', 32624), ('the', 46654), ('other', 33143), ('reviewers', 38996), ('has', 21177), ('mentioned', 29519), ('that', 46645), ('after', 1404), ('watching', 50735), ('just', 25230), ('oz', 33501), ('episode', 15679), ('you', 52219), ('ll', 27402), ('be', 4335), ('hooked', 22227), ('they', 46753), ('are', 2793), ('right', 39215), ('as', 3012), ('this', 46806), ('is', 24390), ('exactly', 16108), ('what', 51062), ('happened', 21019), ('with', 51540), ('me', 29232), ('br', 6007), ('first', 17476)] \n",
      "\n",
      "(10000, 52522) \n",
      "\n",
      "(2500, 52522) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# set the n-gram range\n",
    "vectorizer = CountVectorizer(ngram_range = (1,1))\n",
    "\n",
    "# create training data representation\n",
    "train_data_cv = vectorizer.fit_transform(train_text)\n",
    "\n",
    "# observe the words in the created dictionary across the document\n",
    "print(len(vectorizer.vocabulary_))\n",
    "print(list(vectorizer.vocabulary_.items())[:30],\"\\n\")\n",
    "\n",
    "print(train_data_cv.shape,\"\\n\") \n",
    "\n",
    "# create test data representation\n",
    "test_data_cv = vectorizer.transform(test_text)\n",
    "print(test_data_cv.shape,\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b1dcb",
   "metadata": {},
   "source": [
    "What is the number of features? Note that it is quite large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd0b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, auc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c5701b",
   "metadata": {},
   "source": [
    "### Train and evaluate the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd76f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.84\n",
      "Precision score:  0.8414115204180682\n",
      "Recall score:  0.84\n",
      "F1 score:  0.8397981792031258\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(train_data_cv, y_train)\n",
    "predictions = naive_bayes.predict(test_data_cv)\n",
    "\n",
    "# average could be of 3 kinds = weighted, macro, micro\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, predictions))\n",
    "print(\"Precision score: \", precision_score(y_test, predictions, average=\"weighted\"))\n",
    "print(\"Recall score: \", recall_score(y_test, predictions, average = \"weighted\"))\n",
    "print(\"F1 score: \", f1_score(y_test, predictions, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423fd8a",
   "metadata": {},
   "source": [
    "### Low-variance feature removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7495ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space before filtering:  (10000, 52522)\n",
      "Train feature space after filtering:  (10000, 13136)\n",
      "Test feature space before filtering:  (2500, 52522)\n",
      "Test feature space after filtering:  (2500, 13136)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold = 0.001)\n",
    "\n",
    "X_train_features_filtered_var_thr = selector.fit(train_data_cv).transform(train_data_cv)\n",
    "print (\"Train feature space before filtering: \", train_data_cv.shape)\n",
    "print (\"Train feature space after filtering: \", X_train_features_filtered_var_thr.shape)\n",
    "\n",
    "X_test_features_filtered_var_thr = selector.transform(test_data_cv)\n",
    "print (\"Test feature space before filtering: \", test_data_cv.shape)\n",
    "print (\"Test feature space after filtering: \", X_test_features_filtered_var_thr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d626969",
   "metadata": {},
   "source": [
    "What happened with low-variance feature removal? What does the results tell you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ed405",
   "metadata": {},
   "source": [
    "Experiment with different variance threshold values and observe how the number of features changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65526c07",
   "metadata": {},
   "source": [
    "### Feature selection using chi-squared statistic and k-best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e4cec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space before filtering:  (10000, 52522)\n",
      "Train feature space after filtering:  (10000, 200)\n",
      "Test feature space before filtering:  (2500, 52522)\n",
      "Test feature space after filtering:  (2500, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# chi-square test measures how strongly each feature (word) is dependent on the target label\n",
    "# 'Is the occurrence of this word independent of the class label, or not?' -> Discriminative power\n",
    "selector = SelectKBest(chi2, k=200)\n",
    "\n",
    "X_train_features_filtered_kbest = selector.fit_transform(train_data_cv, y_train)\n",
    "print (\"Train feature space before filtering: \", train_data_cv.shape)\n",
    "print (\"Train feature space after filtering: \", X_train_features_filtered_kbest.shape)\n",
    "\n",
    "X_test_features_filtered_kbest = selector.transform(test_data_cv)\n",
    "print (\"Test feature space before filtering: \", test_data_cv.shape)\n",
    "print (\"Test feature space after filtering: \", X_test_features_filtered_kbest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732948a2",
   "metadata": {},
   "source": [
    "### Training and evaluating a model with selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748f3d2",
   "metadata": {},
   "source": [
    "Use the code from above to train and evaluate a model. Only this time with the `X_train_features_filtered_var_thr` and  `X_test_features_filtered_var_thr` (features selected after low-variance feature removal). Compare the results with the earlier model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ef204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your training/evaluation code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff70a0f",
   "metadata": {},
   "source": [
    "You can train/evaluate the model with features selected using chi-squared statistic, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb56f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your training/evaluation code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42bd5cd",
   "metadata": {},
   "source": [
    "### Model-based feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4143f",
   "metadata": {},
   "source": [
    "Here we select features for a logistic regression model with L1 (LASSO) regularization, which implicitly performs feature selection by setting feature weights to zero. See the below code and interpret the printed outputs in the cell. The selector is using an estimator to keep the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a01d33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of the features fed to the  LogisticRegression(penalty='l1', solver='liblinear')  estimator\n",
      "[[ 0.        -0.0572272  0.        ...  0.         0.         0.       ]]\n",
      "\n",
      "selector.threshold_  1e-05\n",
      "\n",
      "Selector support:  [False  True False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "selector = SelectFromModel(\n",
    "    estimator=LogisticRegression(solver=\"liblinear\", penalty=\"l1\")\n",
    ").fit(train_data_cv, y_train)\n",
    "\n",
    "# estimator_: The base estimator from which the transformer is built. This attribute exists only when fit has been called.\n",
    "# In this case, the estimator is Logistic Regression.\n",
    "# coef_ : an attribute of the Logistic Regression estimator. Tha value represents the weight of each of the features fed to the model.\n",
    "print(\"Coefficients of the features fed to the \",selector.estimator_ , \" estimator\")\n",
    "print(selector.estimator_.coef_)\n",
    "\n",
    "# threshold_: Threshold value used for feature selection.\n",
    "print(\"\\nselector.threshold_ \", selector.threshold_)\n",
    "\n",
    "# Can you try to change the threshold as you want?\n",
    "\n",
    "# Print the features which were kept or dropped after regularization.\n",
    "print(\"\\nSelector support: \", selector.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb20aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space before filtering:  (10000, 52522)\n",
      "Train feature space after filtering:  (10000, 2258)\n",
      "Test feature space before filtering:  (2500, 52522)\n",
      "Test feature space after filtering:  (2500, 2258)\n"
     ]
    }
   ],
   "source": [
    "train_data_cv_selectedfrommodel = selector.transform(train_data_cv)\n",
    "test_data_cv_selectedfrommodel = selector.transform(test_data_cv)\n",
    "\n",
    "print (\"Train feature space before filtering: \", train_data_cv.shape)\n",
    "print (\"Train feature space after filtering: \", train_data_cv_selectedfrommodel.shape)\n",
    "print (\"Test feature space before filtering: \", test_data_cv.shape)\n",
    "print (\"Test feature space after filtering: \", test_data_cv_selectedfrommodel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88bc4f",
   "metadata": {},
   "source": [
    "### Creating pipelines in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ecc1e",
   "metadata": {},
   "source": [
    "scikit-learn pipelines can be used to specify multiple steps in a data modeling process and execute them in sequence. The pipeline below does feature selection, then builds a multinomial NB model using the selected features. \n",
    "\n",
    "It is possible to add more steps to the pipeline such as StandardScaler. You can read more about the scikit-learn Pipeline here- https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a109f43",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"How can such good actors like Jean Rochefort and Carole Bouquet could have been involved in such a... a... well, such a thing ? I can't get it. It was awful, very baldy played (but some of the few leading roles), the jokes are dumb and absolutely not funny... I won't talk more about this movie, except for one little piece of advice : Do not go see it, it will be a waste of time and money.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      4\u001b[39m x_train, x_valid, y_train, y_valid = train_test_split(\n\u001b[32m      5\u001b[39m     train_data_df[\u001b[33m'\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m'\u001b[39m], train_data_df[\u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m], test_size=\u001b[32m0.2\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m pipeline = Pipeline(\n\u001b[32m      9\u001b[39m     [(\u001b[33m'\u001b[39m\u001b[33mvar_th\u001b[39m\u001b[33m'\u001b[39m, VarianceThreshold(threshold=\u001b[32m0.001\u001b[39m)), (\u001b[33m'\u001b[39m\u001b[33mmnb\u001b[39m\u001b[33m'\u001b[39m, MultinomialNB())], \n\u001b[32m     10\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     11\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m pipeline.fit(x_train, y_train)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# to see all the hyper parameters\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/pipeline.py:469\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[32m    427\u001b[39m \n\u001b[32m    428\u001b[39m \u001b[33;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    466\u001b[39m \u001b[33;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    468\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m Xt = \u001b[38;5;28mself\u001b[39m._fit(X, y, routed_params)\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/pipeline.py:406\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params)\u001b[39m\n\u001b[32m    404\u001b[39m     cloned_transformer = clone(transformer)\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m X, fitted_transformer = fit_transform_one_cached(\n\u001b[32m    407\u001b[39m     cloned_transformer,\n\u001b[32m    408\u001b[39m     X,\n\u001b[32m    409\u001b[39m     y,\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    411\u001b[39m     message_clsname=\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    412\u001b[39m     message=\u001b[38;5;28mself\u001b[39m._log_message(step_idx),\n\u001b[32m    413\u001b[39m     params=routed_params[name],\n\u001b[32m    414\u001b[39m )\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/pipeline.py:1310\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1308\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m         res = transformer.fit_transform(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m, {}))\n\u001b[32m   1311\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1312\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1313\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1314\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = f(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/base.py:1101\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m   1098\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1100\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1466\u001b[39m     estimator._validate_params()\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1469\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1470\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1471\u001b[39m     )\n\u001b[32m   1472\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/feature_selection/_variance_threshold.py:99\u001b[39m, in \u001b[36mVarianceThreshold.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Learn empirical variances from X.\u001b[39;00m\n\u001b[32m     83\u001b[39m \n\u001b[32m     84\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     97\u001b[39m \u001b[33;03m        Returns the instance itself.\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     X = \u001b[38;5;28mself\u001b[39m._validate_data(\n\u001b[32m    100\u001b[39m         X,\n\u001b[32m    101\u001b[39m         accept_sparse=(\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    102\u001b[39m         dtype=np.float64,\n\u001b[32m    103\u001b[39m         force_all_finite=\u001b[33m\"\u001b[39m\u001b[33mallow-nan\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    104\u001b[39m     )\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m\"\u001b[39m\u001b[33mtoarray\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# sparse matrix\u001b[39;00m\n\u001b[32m    107\u001b[39m         _, \u001b[38;5;28mself\u001b[39m.variances_ = mean_variance_axis(X, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/base.py:633\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    631\u001b[39m         out = X, y\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     out = check_array(X, input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m, **check_params)\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m    635\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/utils/validation.py:1012\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1010\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1011\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m         array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1014\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1015\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1016\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/sklearn/utils/_array_api.py:745\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    743\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/textmining/lib/python3.12/site-packages/pandas/core/series.py:1031\u001b[39m, in \u001b[36mSeries.__array__\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    982\u001b[39m \u001b[33;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[32m    983\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1028\u001b[39m \u001b[33;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[32m   1029\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1030\u001b[39m values = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m arr = np.asarray(values, dtype=dtype)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values.dtype, arr.dtype):\n\u001b[32m   1033\u001b[39m     arr = arr.view()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: \"How can such good actors like Jean Rochefort and Carole Bouquet could have been involved in such a... a... well, such a thing ? I can't get it. It was awful, very baldy played (but some of the few leading roles), the jokes are dumb and absolutely not funny... I won't talk more about this movie, except for one little piece of advice : Do not go see it, it will be a waste of time and money.\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data_cv, y_train, test_size=0.2)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [('var_th', VarianceThreshold(threshold=0.001)), ('mnb', MultinomialNB())], \n",
    "    verbose=True\n",
    ")\n",
    " \n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# to see all the hyper parameters\n",
    "print()\n",
    "print(pipeline.get_params())\n",
    "\n",
    "print(\"\\nEvaluation accuracy: \", pipeline.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8612b1",
   "metadata": {},
   "source": [
    "### Stratified k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b2f0a",
   "metadata": {},
   "source": [
    "Below is an example of how the stratified k-fold cross-validation divides the data into training and test sets based on the value of number of splits. You can update this code further to incorporate the model training and evaluation for each split and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96de1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_all_text = train_data_df[\"review\"]\n",
    "y_all = train_data_df[\"sentiment\"]\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "x_all = vectorizer.fit_transform(x_all_text)\n",
    "\n",
    "print(len(vectorizer.vocabulary_))\n",
    "print(list(vectorizer.vocabulary_.items())[:30],\"\\n\")\n",
    "\n",
    "print(x_all.shape,\"\\n\") \n",
    "print(y_all.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a67b895-2073-43e3-aa39-a1a4cb63f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in skf.split(x_all, y_all):\n",
    "    \n",
    "    X_train = x_all[train_index]\n",
    "    X_test = x_all[test_index]\n",
    "    Y_train = y_all[train_index]\n",
    "    Y_test = y_all[test_index]\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [('chi2', SelectKBest(chi2, k=200)), ('mnb', MultinomialNB())], \n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    pipeline.fit(X_train, Y_train)\n",
    "\n",
    "    # to see all the hyper parameters\n",
    "    print()\n",
    "    print(pipeline.get_params())\n",
    "\n",
    "    print(\"\\nEvaluation accuracy: \", pipeline.score(X_test, Y_test))\n",
    "    print(\"\\n\\n.........................\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf98339",
   "metadata": {},
   "source": [
    "Below is a one liner code to implement an ML pipeline with Sklearn Pipeline and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('chi2', SelectKBest(chi2, k=200)),('mnb', MultinomialNB())], verbose=True)\n",
    "scores = cross_val_score(pipeline, x_all, y_all, cv=5)\n",
    "\n",
    "print(\"\\nScores of the K fold stratified cross validations= \", scores)\n",
    "print(\"Average score of the K fold stratified cross validation= \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b62854",
   "metadata": {},
   "source": [
    "# 2. Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4566b5e",
   "metadata": {},
   "source": [
    "### Count-based feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf841b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "x_all_text = train_data_df[\"review\"]\n",
    "y_all = train_data_df[\"sentiment\"]\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "# set the n-gram range\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "\n",
    "# create training data representation\n",
    "x_all = vectorizer.fit_transform(x_all_text)\n",
    "\n",
    "# observe the words in the created dictionary across the document\n",
    "print(len(vectorizer.vocabulary_))\n",
    "print(list(vectorizer.vocabulary_.items())[:30],\"\\n\")\n",
    "\n",
    "print(x_all.shape,\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d12130",
   "metadata": {},
   "source": [
    "### Model comparison across k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46767fc",
   "metadata": {},
   "source": [
    "We train 2 different models (Multinomial Naive Bayes and Logistic Regression) on the complete dataset. We use stratified K-fold to split data into train and test sets with roughly similar proportions of each label. In each fold, we compare the performance of the two models on the same test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3be7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21360f-d6d3-4258-b76d-c80b1ec92181",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "accs_nb = []\n",
    "accs_lr = []\n",
    "\n",
    "for train_index, test_index in skf.split(x_all, y_all):\n",
    "    \n",
    "    X_train = x_all[train_index]\n",
    "    X_test = x_all[test_index]\n",
    "    Y_train = y_all[train_index]\n",
    "    Y_test = y_all[test_index]\n",
    "\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(X_train, Y_train)\n",
    "    predictions_nb = naive_bayes.predict(X_test)\n",
    "\n",
    "    acc_nb = accuracy_score(Y_test, predictions_nb)\n",
    "    accs_nb.append(acc_nb)\n",
    "    \n",
    "    # Logistic Regression\n",
    "    LR = LogisticRegression(solver=\"liblinear\", penalty=\"l1\")\n",
    "    LR.fit(X_train, Y_train)\n",
    "    predictions_lr = LR.predict(X_test)\n",
    "\n",
    "    acc_lr = accuracy_score(Y_test, predictions_lr)\n",
    "    accs_lr.append(acc_lr)\n",
    "    \n",
    "    print(\"Accuracy at fold\", i+1, \"for NB and LR are:\", acc_nb, acc_lr)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83d841",
   "metadata": {},
   "source": [
    "### Measuring statistical significance of the model performance using Student's t-test\n",
    "\n",
    "Because we have results from 10-fold cross validation, we can measure if there's a statistically significant difference between the mean F1 scores of the two classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506875bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Student's t-test \n",
    "nb_lr_ttest = stats.ttest_ind(accs_nb, accs_lr)\n",
    "print(\"t-test result: \", nb_lr_ttest) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3958fe9",
   "metadata": {},
   "source": [
    "What does the result above indicate when the significance level is 95%? How about 99%, or even 99.9%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30194db7-0dc1-4ae6-b0ac-bc95cc72fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a confidence interval for the difference between means of F1 scores of two classifiers.\n",
    "def means_difference(sample1, sample2, axis=-1):\n",
    "    mean1 = np.mean(sample1, axis=axis)\n",
    "    mean2 = np.mean(sample2, axis=axis)\n",
    "    return mean1 - mean2\n",
    "    \n",
    "from scipy.stats import bootstrap\n",
    "res = bootstrap((accs_nb, accs_lr), means_difference)\n",
    "print(res.confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11112d0c-f0d4-492a-8667-120cae49bed7",
   "metadata": {},
   "source": [
    "You can learn more about how to calculate bootstrap confidence intervals here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484da32",
   "metadata": {},
   "source": [
    "We can calculate confidence intervals for accuracy (since we can treat the classification outcome as \"accurate\" or \"not accurate\") of Naive Bayes and logistic regression classifiers. You can learn more about how to calculate confidence intervals for accuracy here: https://machinelearningmastery.com/confidence-intervals-for-machine-learning/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6888f",
   "metadata": {},
   "source": [
    "### Ablation test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23220714",
   "metadata": {},
   "source": [
    "To test how important individual features (or components of a model) are, we can conduct an ablation test.\n",
    "- Train the full model with all features included and conduct evaluation\n",
    "- Remove feature (or group of features) and conduct evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f31fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# use the original training/test split\n",
    "x_train = train_data_df[\"review\"]\n",
    "x_test = test_data_df[\"review\"]\n",
    "y_train = train_data_df[\"sentiment\"]\n",
    "y_test = test_data_df[\"sentiment\"]\n",
    "\n",
    "# we will test different n-gram features for their contribution to logistic regression classifier\n",
    "def ablation_test(x_train, y_train, x_test, y_test, ngram_range):\n",
    "    vectorizer = CountVectorizer(ngram_range = ngram_range)\n",
    "\n",
    "    # create training data representation\n",
    "    grams = vectorizer.fit(x_train)\n",
    "    \n",
    "    x_train = vectorizer.transform(x_train)\n",
    "    x_test = vectorizer.transform(x_test)\n",
    "    \n",
    "    # observe the words in the created dictionary across the document\n",
    "    print(\"number of features for ngram_range \", ngram_range, \" : \",len(vectorizer.vocabulary_))\n",
    "\n",
    "    LR = LogisticRegression(solver=\"liblinear\", penalty=\"l1\")\n",
    "    LR.fit(x_train, y_train)\n",
    "    predictions_lr = LR.predict(x_test)\n",
    "\n",
    "    f1_lr = f1_score(y_test, predictions_lr, average = \"weighted\")\n",
    "    print(\"F1 score for \", ngram_range, \" : \",f1_lr, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ablation test for unigrams, unigrams+bigrams, unigrams+bigrams+trigrams, etc.\n",
    "for i in range(1, 4):\n",
    "    for j in range(3, 0, -1): \n",
    "        if i <= j:\n",
    "            ablation_test(x_train, y_train, x_test, y_test, (i, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76413e9",
   "metadata": {},
   "source": [
    "What do the results indicate? Which n-gram feature is most useful? least useful? Do the results align with your expectations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "textmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
