{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d837aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries here that you need for different processing steps\n",
    "import nltk\n",
    "import csv\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5e095",
   "metadata": {},
   "source": [
    "## Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae82974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file into a dataframe\n",
    "data_file = \"./Dataset/covid.csv\"\n",
    "\n",
    "data_df = pd.read_csv(data_file)\n",
    "print (\"Training set: \", len(data_df))\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44617d37",
   "metadata": {},
   "source": [
    "## Basic Data Cleaning and Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1c1bb",
   "metadata": {},
   "source": [
    "## Counting Sentiment Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell to see the distribution of the sentiment label in the dataset\n",
    "print(data_df.Sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90843e73",
   "metadata": {},
   "source": [
    "## Dropping Columns\n",
    "Identify the column that are less relevant for text mining or other NLP tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(['ScreenName', 'TweetAt'], axis=1, inplace=True)\n",
    "print(data_df.shape)\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db92ceec",
   "metadata": {},
   "source": [
    "## Handling NULL values\n",
    "Handle null values in a column by specifying the alternate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to fill all null values in all columns of the dataframe with the desired value. \n",
    "# Trying doing it for a single column yourself.\n",
    "\n",
    "data_df = data_df.fillna(\"NA\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ccc0eb",
   "metadata": {},
   "source": [
    "## Handling Exceptions\n",
    "Use try-except-pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate the statements within a try-except block where you suspect there might be errors.\n",
    "# In the except block, handle the exception according to the requirement.\n",
    "\n",
    "try:\n",
    "    data_df = data_df.fillna(\"NA\")\n",
    "except:\n",
    "    # Implement your ideas how to bypass potential errors\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ed35f",
   "metadata": {},
   "source": [
    "## Lowercase conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cb3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing lower case conversion of Tweet for an instance\n",
    "\n",
    "print(data_df.OriginalTweet.tolist()[100])\n",
    "print(\"\\n\")\n",
    "print(data_df.OriginalTweet.tolist()[100].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b677c9ff",
   "metadata": {},
   "source": [
    "## Handling Special Characters or links\n",
    "\n",
    "This should be an interesting step. You can remove special characters or links or anything that does not have value for the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing removal of special chars from the Tweet for an instance\n",
    "\n",
    "import re\n",
    "\n",
    "print(data_df.OriginalTweet.tolist()[100])\n",
    "print(\"\\n\")\n",
    "print(re.sub('[^A-Za-z0-9]+', ' ', data_df.OriginalTweet.tolist()[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed658a1",
   "metadata": {},
   "source": [
    "## Text Pre-processing\n",
    "\n",
    "The following are the techniques to tranform the data into a cleaner data. Try out the what all techniques you would apply to your textual data to get the best quality dataset for a model.\n",
    "You can use either/all/addition to these steps mentioned below in any order that you find appropriate.\n",
    "\n",
    "- Tokenization\n",
    "- Sentence Segmentation\n",
    "\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- PartOfSpeech Tagging\n",
    "- Others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30dee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see an example of text pre-processing including a few of these techniques. \n",
    "# This image is a hint to the pre-processing steps but may or may not be the best. \n",
    "# It shows how the input text changes with each processing step\n",
    "# Find out different Tokenizers, Stemmers, Lemmatizers, etc and try to use the best one for your task! \n",
    "\n",
    "from PIL import Image\n",
    "pil_im = Image.open('./Dataset/Text_preprocessing_example.png')\n",
    "pil_im = pil_im.convert(\"RGB\")\n",
    "display(pil_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e19a52",
   "metadata": {},
   "source": [
    "## Tokenization using nltk library\n",
    " Links to a few word and sentence tokenizers- https://www.nltk.org/howto/tokenize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6acc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing tokenization of the Tweets into words for an instance\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print(data_df.OriginalTweet.tolist()[100])\n",
    "print(\"\\n\")\n",
    "print(word_tokenize(data_df.OriginalTweet.tolist()[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd61b1",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Links to a few nltk Stemmers- https://www.nltk.org/howto/stem.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea048344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing stemming of words\n",
    "\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "\n",
    "print(data_df.OriginalTweet.tolist()[51])\n",
    "print(\"\\n\")\n",
    "\n",
    "tweet = data_df.OriginalTweet.tolist()[51].split()\n",
    "\n",
    "for word in tweet:\n",
    "    print(word, \" \", ps.stem(word) ,\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d39c8-8a1f-45dd-8d72-72b26f4c0e4d",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "\n",
    "- Some special characters or symbols may not be useful, but others (e.g., hashtags, question marks, emojis) might carry important information. How would you decide what to remove and what to keep?\n",
    "- Lowercasing is often applied as a default step. Can you think of cases where preserving case (uppercase vs lowercase) might be important for text mining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c19ef3-68e9-4702-8a43-b6e13d983b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "textmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
